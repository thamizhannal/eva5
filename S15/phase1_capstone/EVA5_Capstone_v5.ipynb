{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA5_Capstone_v5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1gVZUFQmc8p",
        "outputId": "4357760c-5702-4a7d-9d28-6bbbe15bacb5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zGjh1_QmsAa",
        "outputId": "5a748866-ba7c-4b4d-caf4-494668542207"
      },
      "source": [
        "!ls /content/gdrive/'My Drive'/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best.pt  last_ppe.pt  last.pt  model-f46da743.pt  yolov3-spp-ultralytics.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_6sYY8Pnavp",
        "outputId": "ec98c2a6-3b6d-4374-de45-75a519a118b5"
      },
      "source": [
        "%cd /content/gdrive/'My Drive'/SchoolOfAI_EVA/phase1_capstone"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/SchoolOfAI_EVA/phase1_capstone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym8AemE4nxXo",
        "outputId": "70d41fa4-1387-4f0b-838f-95c3f2c8f681"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apex\t       depth_loss.py\t\tmodel_yolo.py\t      test.py\n",
            "base_model.py  encoder_decoder_arch.py\tpranav_train_fork.py  util_depth.py\n",
            "blocks.py      fork_train.py\t\t__pycache__\t      utils_yolo\n",
            "cfg_yolo       model.py\t\t\truns\t\t      yolo_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlY5jHVxg07w",
        "outputId": "b488ca8d-bb7d-45d2-d395-993d105719c8"
      },
      "source": [
        "!ls /content/gdrive/'My Drive'/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/model-f46da743.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/model-f46da743.pt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQKEu84-8MdG"
      },
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoFDYaf0mdae",
        "outputId": "140cf32f-2e68-4866-8113-37aa5c398d33"
      },
      "source": [
        "from model import *\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = fork(depth_freeze = False, yolo_freeze = True,depth_preload_pth = '', yolo_preload_pth = '/content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/last_ppe.pt').to(device)\n",
        "from torchsummary import summary\n",
        "print(summary(model, (3,416,416)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "encoder loaded weights from /content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/model-f46da743.pt\n",
            "resnet_layer 0 was frozen\n",
            "resnet_layer 1 was frozen\n",
            "resnet_layer 2 was frozen\n",
            "resnet_layer 3 was frozen\n",
            "loaded weight from /content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/last_ppe.pt\n",
            "yolo_decoder loaded from /content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/last_ppe.pt\n",
            "yolo_layer 0 was frozen\n",
            "yolo_layer 1 was frozen\n",
            "yolo_layer 2 was frozen\n",
            "yolo_layer 3 was frozen\n",
            "yolo_layer 4 was frozen\n",
            "yolo_layer 5 was frozen\n",
            "yolo_layer 6 was frozen\n",
            "yolo_layer 7 was frozen\n",
            "yolo_layer 8 was frozen\n",
            "yolo_layer 9 was frozen\n",
            "yolo_layer 10 was frozen\n",
            "yolo_layer 11 was frozen\n",
            "yolo_layer 12 was frozen\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 208, 208]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 208, 208]             128\n",
            "              ReLU-3         [-1, 64, 208, 208]               0\n",
            "         MaxPool2d-4         [-1, 64, 104, 104]               0\n",
            "            Conv2d-5        [-1, 256, 104, 104]          16,384\n",
            "       BatchNorm2d-6        [-1, 256, 104, 104]             512\n",
            "              ReLU-7        [-1, 256, 104, 104]               0\n",
            "            Conv2d-8        [-1, 256, 104, 104]          18,432\n",
            "       BatchNorm2d-9        [-1, 256, 104, 104]             512\n",
            "             ReLU-10        [-1, 256, 104, 104]               0\n",
            "           Conv2d-11        [-1, 256, 104, 104]          65,536\n",
            "      BatchNorm2d-12        [-1, 256, 104, 104]             512\n",
            "           Conv2d-13        [-1, 256, 104, 104]          16,384\n",
            "      BatchNorm2d-14        [-1, 256, 104, 104]             512\n",
            "             ReLU-15        [-1, 256, 104, 104]               0\n",
            "       Bottleneck-16        [-1, 256, 104, 104]               0\n",
            "           Conv2d-17        [-1, 256, 104, 104]          65,536\n",
            "      BatchNorm2d-18        [-1, 256, 104, 104]             512\n",
            "             ReLU-19        [-1, 256, 104, 104]               0\n",
            "           Conv2d-20        [-1, 256, 104, 104]          18,432\n",
            "      BatchNorm2d-21        [-1, 256, 104, 104]             512\n",
            "             ReLU-22        [-1, 256, 104, 104]               0\n",
            "           Conv2d-23        [-1, 256, 104, 104]          65,536\n",
            "      BatchNorm2d-24        [-1, 256, 104, 104]             512\n",
            "             ReLU-25        [-1, 256, 104, 104]               0\n",
            "       Bottleneck-26        [-1, 256, 104, 104]               0\n",
            "           Conv2d-27        [-1, 256, 104, 104]          65,536\n",
            "      BatchNorm2d-28        [-1, 256, 104, 104]             512\n",
            "             ReLU-29        [-1, 256, 104, 104]               0\n",
            "           Conv2d-30        [-1, 256, 104, 104]          18,432\n",
            "      BatchNorm2d-31        [-1, 256, 104, 104]             512\n",
            "             ReLU-32        [-1, 256, 104, 104]               0\n",
            "           Conv2d-33        [-1, 256, 104, 104]          65,536\n",
            "      BatchNorm2d-34        [-1, 256, 104, 104]             512\n",
            "             ReLU-35        [-1, 256, 104, 104]               0\n",
            "       Bottleneck-36        [-1, 256, 104, 104]               0\n",
            "           Conv2d-37        [-1, 512, 104, 104]         131,072\n",
            "      BatchNorm2d-38        [-1, 512, 104, 104]           1,024\n",
            "             ReLU-39        [-1, 512, 104, 104]               0\n",
            "           Conv2d-40          [-1, 512, 52, 52]          73,728\n",
            "      BatchNorm2d-41          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-42          [-1, 512, 52, 52]               0\n",
            "           Conv2d-43          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-44          [-1, 512, 52, 52]           1,024\n",
            "           Conv2d-45          [-1, 512, 52, 52]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-47          [-1, 512, 52, 52]               0\n",
            "       Bottleneck-48          [-1, 512, 52, 52]               0\n",
            "           Conv2d-49          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-50          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-51          [-1, 512, 52, 52]               0\n",
            "           Conv2d-52          [-1, 512, 52, 52]          73,728\n",
            "      BatchNorm2d-53          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-54          [-1, 512, 52, 52]               0\n",
            "           Conv2d-55          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-56          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-57          [-1, 512, 52, 52]               0\n",
            "       Bottleneck-58          [-1, 512, 52, 52]               0\n",
            "           Conv2d-59          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-60          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-61          [-1, 512, 52, 52]               0\n",
            "           Conv2d-62          [-1, 512, 52, 52]          73,728\n",
            "      BatchNorm2d-63          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-64          [-1, 512, 52, 52]               0\n",
            "           Conv2d-65          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-66          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-67          [-1, 512, 52, 52]               0\n",
            "       Bottleneck-68          [-1, 512, 52, 52]               0\n",
            "           Conv2d-69          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-70          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-71          [-1, 512, 52, 52]               0\n",
            "           Conv2d-72          [-1, 512, 52, 52]          73,728\n",
            "      BatchNorm2d-73          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-74          [-1, 512, 52, 52]               0\n",
            "           Conv2d-75          [-1, 512, 52, 52]         262,144\n",
            "      BatchNorm2d-76          [-1, 512, 52, 52]           1,024\n",
            "             ReLU-77          [-1, 512, 52, 52]               0\n",
            "       Bottleneck-78          [-1, 512, 52, 52]               0\n",
            "           Conv2d-79         [-1, 1024, 52, 52]         524,288\n",
            "      BatchNorm2d-80         [-1, 1024, 52, 52]           2,048\n",
            "             ReLU-81         [-1, 1024, 52, 52]               0\n",
            "           Conv2d-82         [-1, 1024, 26, 26]         294,912\n",
            "      BatchNorm2d-83         [-1, 1024, 26, 26]           2,048\n",
            "             ReLU-84         [-1, 1024, 26, 26]               0\n",
            "           Conv2d-85         [-1, 1024, 26, 26]       1,048,576\n",
            "      BatchNorm2d-86         [-1, 1024, 26, 26]           2,048\n",
            "           Conv2d-87         [-1, 1024, 26, 26]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 26, 26]           2,048\n",
            "             ReLU-89         [-1, 1024, 26, 26]               0\n",
            "       Bottleneck-90         [-1, 1024, 26, 26]               0\n",
            "           Conv2d-91         [-1, 1024, 26, 26]       1,048,576\n",
            "      BatchNorm2d-92         [-1, 1024, 26, 26]           2,048\n",
            "             ReLU-93         [-1, 1024, 26, 26]               0\n",
            "           Conv2d-94         [-1, 1024, 26, 26]         294,912\n",
            "      BatchNorm2d-95         [-1, 1024, 26, 26]           2,048\n",
            "             ReLU-96         [-1, 1024, 26, 26]               0\n",
            "           Conv2d-97         [-1, 1024, 26, 26]       1,048,576\n",
            "      BatchNorm2d-98         [-1, 1024, 26, 26]           2,048\n",
            "             ReLU-99         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-100         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-101         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-102         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-103         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-104         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-105         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-106         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-107         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-108         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-109         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-110         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-111         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-112         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-113         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-114         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-115         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-116         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-117         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-118         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-119         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-120         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-121         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-122         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-123         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-124         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-125         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-126         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-127         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-128         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-129         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-130         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-131         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-132         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-133         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-134         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-135         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-136         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-137         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-138         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-139         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-140         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-141         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-142         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-143         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-144         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-145         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-146         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-147         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-148         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-149         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-150         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-151         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-152         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-153         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-154         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-155         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-156         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-157         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-158         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-159         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-160         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-161         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-162         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-163         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-164         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-165         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-166         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-167         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-168         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-169         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-170         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-171         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-172         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-173         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-174         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-175         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-176         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-177         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-178         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-179         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-180         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-181         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-182         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-183         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-184         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-185         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-186         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-187         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-188         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-189         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-190         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-191         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-192         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-193         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-194         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-195         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-196         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-197         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-198         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-199         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-200         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-201         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-202         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-203         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-204         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-205         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-206         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-207         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-208         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-209         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-210         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-211         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-212         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-213         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-214         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-215         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-216         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-217         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-218         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-219         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-220         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-221         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-222         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-223         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-224         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-225         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-226         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-227         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-228         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-229         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-230         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-231         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-232         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-233         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-234         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-235         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-236         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-237         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-238         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-239         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-240         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-241         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-242         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-243         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-244         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-245         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-246         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-247         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-248         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-249         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-250         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-251         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-252         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-253         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-254         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-255         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-256         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-257         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-258         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-259         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-260         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-261         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-262         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-263         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-264         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-265         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-266         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-267         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-268         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-269         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-270         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-271         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-272         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-273         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-274         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-275         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-276         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-277         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-278         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-279         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-280         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-281         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-282         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-283         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-284         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-285         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-286         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-287         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-288         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-289         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-290         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-291         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-292         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-293         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-294         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-295         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-296         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-297         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-298         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-299         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-300         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-301         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-302         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-303         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-304         [-1, 1024, 26, 26]         294,912\n",
            "     BatchNorm2d-305         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-306         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-307         [-1, 1024, 26, 26]       1,048,576\n",
            "     BatchNorm2d-308         [-1, 1024, 26, 26]           2,048\n",
            "            ReLU-309         [-1, 1024, 26, 26]               0\n",
            "      Bottleneck-310         [-1, 1024, 26, 26]               0\n",
            "          Conv2d-311         [-1, 2048, 26, 26]       2,097,152\n",
            "     BatchNorm2d-312         [-1, 2048, 26, 26]           4,096\n",
            "            ReLU-313         [-1, 2048, 26, 26]               0\n",
            "          Conv2d-314         [-1, 2048, 13, 13]       1,179,648\n",
            "     BatchNorm2d-315         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-316         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-317         [-1, 2048, 13, 13]       4,194,304\n",
            "     BatchNorm2d-318         [-1, 2048, 13, 13]           4,096\n",
            "          Conv2d-319         [-1, 2048, 13, 13]       2,097,152\n",
            "     BatchNorm2d-320         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-321         [-1, 2048, 13, 13]               0\n",
            "      Bottleneck-322         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-323         [-1, 2048, 13, 13]       4,194,304\n",
            "     BatchNorm2d-324         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-325         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-326         [-1, 2048, 13, 13]       1,179,648\n",
            "     BatchNorm2d-327         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-328         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-329         [-1, 2048, 13, 13]       4,194,304\n",
            "     BatchNorm2d-330         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-331         [-1, 2048, 13, 13]               0\n",
            "      Bottleneck-332         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-333         [-1, 2048, 13, 13]       4,194,304\n",
            "     BatchNorm2d-334         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-335         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-336         [-1, 2048, 13, 13]       1,179,648\n",
            "     BatchNorm2d-337         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-338         [-1, 2048, 13, 13]               0\n",
            "          Conv2d-339         [-1, 2048, 13, 13]       4,194,304\n",
            "     BatchNorm2d-340         [-1, 2048, 13, 13]           4,096\n",
            "            ReLU-341         [-1, 2048, 13, 13]               0\n",
            "      Bottleneck-342         [-1, 2048, 13, 13]               0\n",
            "             enc-343  [[-1, 256, 104, 104], [-1, 512, 52, 52], [-1, 1024, 26, 26], [-1, 2048, 13, 13]]               0\n",
            "          Conv2d-344        [-1, 256, 104, 104]         589,824\n",
            "          Conv2d-345          [-1, 256, 52, 52]       1,179,648\n",
            "          Conv2d-346          [-1, 256, 26, 26]       2,359,296\n",
            "          Conv2d-347          [-1, 256, 13, 13]       4,718,592\n",
            "            ReLU-348          [-1, 256, 13, 13]               0\n",
            "          Conv2d-349          [-1, 256, 13, 13]         590,080\n",
            "            ReLU-350          [-1, 256, 13, 13]               0\n",
            "          Conv2d-351          [-1, 256, 13, 13]         590,080\n",
            "ResidualConvUnit-352          [-1, 256, 13, 13]               0\n",
            "FeatureFusionBlock-353          [-1, 256, 26, 26]               0\n",
            "            ReLU-354          [-1, 256, 26, 26]               0\n",
            "          Conv2d-355          [-1, 256, 26, 26]         590,080\n",
            "            ReLU-356          [-1, 256, 26, 26]               0\n",
            "          Conv2d-357          [-1, 256, 26, 26]         590,080\n",
            "ResidualConvUnit-358          [-1, 256, 26, 26]               0\n",
            "            ReLU-359          [-1, 256, 26, 26]               0\n",
            "          Conv2d-360          [-1, 256, 26, 26]         590,080\n",
            "            ReLU-361          [-1, 256, 26, 26]               0\n",
            "          Conv2d-362          [-1, 256, 26, 26]         590,080\n",
            "ResidualConvUnit-363          [-1, 256, 26, 26]               0\n",
            "FeatureFusionBlock-364          [-1, 256, 52, 52]               0\n",
            "            ReLU-365          [-1, 256, 52, 52]               0\n",
            "          Conv2d-366          [-1, 256, 52, 52]         590,080\n",
            "            ReLU-367          [-1, 256, 52, 52]               0\n",
            "          Conv2d-368          [-1, 256, 52, 52]         590,080\n",
            "ResidualConvUnit-369          [-1, 256, 52, 52]               0\n",
            "            ReLU-370          [-1, 256, 52, 52]               0\n",
            "          Conv2d-371          [-1, 256, 52, 52]         590,080\n",
            "            ReLU-372          [-1, 256, 52, 52]               0\n",
            "          Conv2d-373          [-1, 256, 52, 52]         590,080\n",
            "ResidualConvUnit-374          [-1, 256, 52, 52]               0\n",
            "FeatureFusionBlock-375        [-1, 256, 104, 104]               0\n",
            "            ReLU-376        [-1, 256, 104, 104]               0\n",
            "          Conv2d-377        [-1, 256, 104, 104]         590,080\n",
            "            ReLU-378        [-1, 256, 104, 104]               0\n",
            "          Conv2d-379        [-1, 256, 104, 104]         590,080\n",
            "ResidualConvUnit-380        [-1, 256, 104, 104]               0\n",
            "            ReLU-381        [-1, 256, 104, 104]               0\n",
            "          Conv2d-382        [-1, 256, 104, 104]         590,080\n",
            "            ReLU-383        [-1, 256, 104, 104]               0\n",
            "          Conv2d-384        [-1, 256, 104, 104]         590,080\n",
            "ResidualConvUnit-385        [-1, 256, 104, 104]               0\n",
            "FeatureFusionBlock-386        [-1, 256, 208, 208]               0\n",
            "          Conv2d-387        [-1, 128, 208, 208]         295,040\n",
            "     Interpolate-388        [-1, 128, 416, 416]               0\n",
            "          Conv2d-389         [-1, 32, 416, 416]          36,896\n",
            "            ReLU-390         [-1, 32, 416, 416]               0\n",
            "          Conv2d-391          [-1, 1, 416, 416]              33\n",
            "            ReLU-392          [-1, 1, 416, 416]               0\n",
            "   depth_decoder-393             [-1, 416, 416]               0\n",
            "          Conv2d-394         [-1, 2048, 13, 13]       4,194,304\n",
            "          Conv2d-395          [-1, 512, 13, 13]       1,048,576\n",
            "     BatchNorm2d-396          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-397          [-1, 512, 13, 13]               0\n",
            "          Conv2d-398         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-399         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-400         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-401          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-402          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-403          [-1, 512, 13, 13]               0\n",
            "          Conv2d-404         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-405         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-406         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-407           [-1, 27, 13, 13]          27,675\n",
            "       YOLOLayer-408         [-1, 3, 13, 13, 9]               0\n",
            "          Conv2d-409          [-1, 256, 13, 13]         131,072\n",
            "     BatchNorm2d-410          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-411          [-1, 256, 13, 13]               0\n",
            "        Upsample-412          [-1, 256, 26, 26]               0\n",
            "          Conv2d-413          [-1, 512, 26, 26]         524,288\n",
            "          Conv2d-414          [-1, 256, 26, 26]         196,608\n",
            "     BatchNorm2d-415          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-416          [-1, 256, 26, 26]               0\n",
            "          Conv2d-417          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-418          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-419          [-1, 512, 26, 26]               0\n",
            "          Conv2d-420          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-421          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-422          [-1, 256, 26, 26]               0\n",
            "          Conv2d-423          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-424          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-425          [-1, 512, 26, 26]               0\n",
            "          Conv2d-426          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-427          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-428          [-1, 256, 26, 26]               0\n",
            "          Conv2d-429          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-430          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-431          [-1, 512, 26, 26]               0\n",
            "          Conv2d-432           [-1, 27, 26, 26]          13,851\n",
            "       YOLOLayer-433         [-1, 3, 26, 26, 9]               0\n",
            "          Conv2d-434          [-1, 128, 26, 26]          32,768\n",
            "     BatchNorm2d-435          [-1, 128, 26, 26]             256\n",
            "       LeakyReLU-436          [-1, 128, 26, 26]               0\n",
            "        Upsample-437          [-1, 128, 52, 52]               0\n",
            "          Conv2d-438          [-1, 256, 52, 52]         131,072\n",
            "          Conv2d-439          [-1, 128, 52, 52]          49,152\n",
            "     BatchNorm2d-440          [-1, 128, 52, 52]             256\n",
            "       LeakyReLU-441          [-1, 128, 52, 52]               0\n",
            "          Conv2d-442          [-1, 256, 52, 52]         294,912\n",
            "     BatchNorm2d-443          [-1, 256, 52, 52]             512\n",
            "       LeakyReLU-444          [-1, 256, 52, 52]               0\n",
            "          Conv2d-445          [-1, 128, 52, 52]          32,768\n",
            "     BatchNorm2d-446          [-1, 128, 52, 52]             256\n",
            "       LeakyReLU-447          [-1, 128, 52, 52]               0\n",
            "          Conv2d-448          [-1, 256, 52, 52]         294,912\n",
            "     BatchNorm2d-449          [-1, 256, 52, 52]             512\n",
            "       LeakyReLU-450          [-1, 256, 52, 52]               0\n",
            "          Conv2d-451          [-1, 128, 52, 52]          32,768\n",
            "     BatchNorm2d-452          [-1, 128, 52, 52]             256\n",
            "       LeakyReLU-453          [-1, 128, 52, 52]               0\n",
            "          Conv2d-454          [-1, 256, 52, 52]         294,912\n",
            "     BatchNorm2d-455          [-1, 256, 52, 52]             512\n",
            "       LeakyReLU-456          [-1, 256, 52, 52]               0\n",
            "          Conv2d-457           [-1, 27, 52, 52]           6,939\n",
            "       YOLOLayer-458         [-1, 3, 52, 52, 9]               0\n",
            "    yolo_decoder-459  [[-1, 3, 13, 13, 9], [-1, 3, 26, 26, 9], [-1, 3, 52, 52, 9]]               0\n",
            "================================================================\n",
            "Total params: 125,265,746\n",
            "Trainable params: 17,440,449\n",
            "Non-trainable params: 107,825,297\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.98\n",
            "Forward/backward pass size (MB): 35467793537158.66\n",
            "Params size (MB): 477.85\n",
            "Estimated Total Size (MB): 35467793537638.48\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Q-b_HhLz34"
      },
      "source": [
        "### Training YoloV3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO7um4_-nVTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5607c490-09dc-4dc2-d2de-82498cda9cc4"
      },
      "source": [
        "!python fork_train.py --data /content/gdrive/'My Drive'/SchoolOfAI_EVA/YoloV3_S13/YoloV3/data/customdata/custom.data --batch 5 --cache --epochs 15 --nosave --train_decoder=yolo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n",
            "Namespace(accumulate=4, adam=False, batch_size=5, bucket='', cache_images=True, cfg='cfg/yolov3-spp.cfg', data='/content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/data/customdata/custom.data', device='', epochs=15, evolve=False, img_size=[512], multi_scale=False, name='', nosave=True, notest=False, rect=False, resume=False, single_cls=False, train_decoder='yolo', weights='weights/yolov3-spp-ultralytics.pt')\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n",
            "\n",
            "2020-12-06 07:25:14.272132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n",
            "im in yolo\n",
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n",
            "encoder loaded weights from /content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/model-f46da743.pt\n",
            "resnet_layer 0 was frozen\n",
            "resnet_layer 1 was frozen\n",
            "resnet_layer 2 was frozen\n",
            "resnet_layer 3 was frozen\n",
            "depth_layer 0 was frozen\n",
            "Caching labels (3064 found, 139 missing, 0 empty, 0 duplicate, for 3203 images): 100% 3203/3203 [00:03<00:00, 1014.31it/s]\n",
            "Caching images (1.8GB): 100% 3203/3203 [00:26<00:00, 118.80it/s]\n",
            "Caching labels (285 found, 0 missing, 0 empty, 0 duplicate, for 286 images): 100% 286/286 [00:00<00:00, 980.03it/s] \n",
            "Caching images (0.1GB): 100% 286/286 [00:03<00:00, 74.33it/s]\n",
            "Image sizes 512 - 512 train, 512 test\n",
            "Using 2 dataloader workers\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "  0% 0/641 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/14     2.97G         0     0.259    0.0259       512:   0% 1/641 [00:03<36:57,  3.47s/it]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/14     3.64G         0       131      13.1       512: 100% 641/641 [08:10<00:00,  1.31it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM:   0% 0/641 [00:00<?, ?it/s]/content/gdrive/My Drive/SchoolOfAI_EVA/phase1_capstone/utils_yolo/utils.py:530: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:15<00:00,  1.29it/s]\n",
            "                 all   3.2e+03   2.1e+04         0         0   7.7e-06         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      1/14     8.68G         0       118      11.8       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:42<00:00,  1.23it/s]\n",
            "                 all   3.2e+03  2.06e+04         0         0  1.18e-06         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      2/14     8.68G         0       115      11.5       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:35<00:00,  1.24it/s]\n",
            "                 all   3.2e+03  2.11e+04         0         0  5.67e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "  0% 0/641 [00:00<?, ?it/s]\n",
            "Model Bias Summary:    layer        regression        objectness    classification\n",
            "      3/14     8.68G         0       108      10.8       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:26<00:00,  1.27it/s]\n",
            "                 all   3.2e+03  2.05e+04         0         0  4.22e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      4/14     8.68G         0       103      10.3       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:03<00:00,  1.33it/s]\n",
            "                 all   3.2e+03   2.1e+04         0         0  3.09e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      5/14     8.68G         0      97.9      9.79       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:45<00:00,  1.38it/s]\n",
            "                 all   3.2e+03   2.1e+04         0         0   6.2e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      6/14     8.68G         0      91.6      9.16       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:45<00:00,  1.38it/s]\n",
            "                 all   3.2e+03  2.07e+04         0         0  1.83e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      7/14     8.68G         0      93.4      9.34       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:42<00:00,  1.39it/s]\n",
            "                 all   3.2e+03  2.14e+04         0         0  6.43e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      8/14     8.68G         0      88.6      8.86       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:38<00:00,  1.40it/s]\n",
            "                 all   3.2e+03  2.05e+04         0         0  7.62e-08         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      9/14     8.68G         0        84       8.4       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:37<00:00,  1.40it/s]\n",
            "                 all   3.2e+03  2.12e+04         0         0   1.6e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "     10/14     8.68G         0      86.6      8.66       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:35<00:00,  1.41it/s]\n",
            "                 all   3.2e+03  2.09e+04         0         0  1.45e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "     11/14     8.68G         0      81.7      8.17       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:37<00:00,  1.40it/s]\n",
            "                 all   3.2e+03  2.09e+04         0         0   1.1e-07         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "     12/14     8.68G         0      79.9      7.99       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:33<00:00,  1.41it/s]\n",
            "                 all   3.2e+03  2.13e+04         0         0  2.31e-08         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "     13/14     8.68G         0      79.9      7.99       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:33<00:00,  1.41it/s]\n",
            "                 all   3.2e+03  2.09e+04         0         0  4.63e-08         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "     14/14     8.68G         0      79.3      7.93       512: 100% 641/641 [08:12<00:00,  1.30it/s]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [07:32<00:00,  1.42it/s]\n",
            "                 all   3.2e+03  2.09e+04         0         0  1.12e-07         0       452\n",
            "No handles with labels found to put in legend.\n",
            "15 epochs completed in 4.039 hours.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUeZHLVtYoq5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXX057f3uYFP"
      },
      "source": [
        "### Traing Yolo and Depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6acNeA2FuagE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94b35a7-0987-4459-8338-11d83b411e7b"
      },
      "source": [
        "!python fork_train.py --cfg /content/gdrive/'My Drive'/SchoolOfAI_EVA/phase1_capstone/cfg_yolo/yolov3-custom.cfg  --data /content/gdrive/'My Drive'/SchoolOfAI_EVA/YoloV3_S13/YoloV3/data/customdata/custom.data --batch 5 --cache --epochs 15 --nosave --train_decoder=all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n",
            "Namespace(accumulate=4, adam=False, batch_size=5, bucket='', cache_images=True, cfg='/content/gdrive/My Drive/SchoolOfAI_EVA/phase1_capstone/cfg_yolo/yolov3-custom.cfg', data='/content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/data/customdata/custom.data', device='', epochs=15, evolve=False, img_size=[512], multi_scale=False, name='', nosave=True, notest=False, rect=False, resume=False, single_cls=False, train_decoder='all', weights='weights/yolov3-spp-ultralytics.pt')\n",
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n",
            "\n",
            "2020-12-06 11:28:40.015314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n",
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n",
            "encoder loaded weights from /content/gdrive/My Drive/SchoolOfAI_EVA/YoloV3_S13/YoloV3/weights/model-f46da743.pt\n",
            "resnet_layer 0 was frozen\n",
            "resnet_layer 1 was frozen\n",
            "resnet_layer 2 was frozen\n",
            "resnet_layer 3 was frozen\n",
            "Caching labels (3064 found, 139 missing, 0 empty, 0 duplicate, for 3203 images): 100% 3203/3203 [00:03<00:00, 1011.32it/s]\n",
            "Caching images (1.8GB): 100% 3203/3203 [00:27<00:00, 114.81it/s]\n",
            "Caching labels (285 found, 0 missing, 0 empty, 0 duplicate, for 286 images): 100% 286/286 [00:00<00:00, 829.19it/s]\n",
            "Caching images (0.1GB): 100% 286/286 [00:04<00:00, 70.23it/s]\n",
            "Image sizes 512 - 512 train, 512 test\n",
            "Using 2 dataloader workers\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "  0% 0/641 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/14     4.18G     0.425     0.259     0.451       512:   0% 1/641 [00:04<47:00,  4.41s/it]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n",
            "      0/14     4.85G       241       131       254       512: 100% 641/641 [14:25<00:00,  1.35s/it]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM:   0% 0/641 [00:00<?, ?it/s]/content/gdrive/My Drive/SchoolOfAI_EVA/phase1_capstone/utils_yolo/utils.py:530: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM: 100% 641/641 [08:19<00:00,  1.28it/s]\n",
            "                 all   3.2e+03   2.1e+04         0         0   7.7e-06         0       452\n",
            "\n",
            "     Epoch   gpu_mem   depthloss   yololoss   finalloss   img_size\n",
            "      1/14     5.92G       240       118       252       512: 100% 641/641 [14:16<00:00,  1.34s/it]\n",
            "               Class    Images   Targets         P         R   mAP@0.5        F1depth_SSIM:  69% 443/641 [06:02<02:44,  1.20it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-7VwbBdug5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
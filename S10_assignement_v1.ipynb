{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "510d309887544e058f8a9a00903d9fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_555548ac556744dd9200fa19fda1c0af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cfde7e08e4840a7af2a196196b8f862",
              "IPY_MODEL_135d27ce59db497ab79c847dcd6a5a0f"
            ]
          }
        },
        "555548ac556744dd9200fa19fda1c0af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cfde7e08e4840a7af2a196196b8f862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b4fd94e7af6444c3af5d5cea9718bd80",
            "_dom_classes": [],
            "description": " 81%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 81,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_674d2fe3063b41c896103e76d54ea377"
          }
        },
        "135d27ce59db497ab79c847dcd6a5a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d54de1ea5e24188b968d369462e95fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 81/100 [00:16&lt;00:03,  5.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b287dddf77e45c18616f59108a7eb4a"
          }
        },
        "b4fd94e7af6444c3af5d5cea9718bd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "674d2fe3063b41c896103e76d54ea377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d54de1ea5e24188b968d369462e95fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b287dddf77e45c18616f59108a7eb4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ae5d68485d442848e34c39f24001adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c48049e83e134da6b6b83fa4f40547ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e26b81ce2e84cdb8f342de558be4c2b",
              "IPY_MODEL_3297671b4e0447fb9449d57cfd88cf92"
            ]
          }
        },
        "c48049e83e134da6b6b83fa4f40547ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e26b81ce2e84cdb8f342de558be4c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb10a63971104ff68f73b41f00a5ee7d",
            "_dom_classes": [],
            "description": " 84%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 84,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f55006915ae3405fbe74dc2c070f925b"
          }
        },
        "3297671b4e0447fb9449d57cfd88cf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c9993ee0023f48dfb6ac5cd57b1c3059",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 84/100 [00:15&lt;00:02,  5.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30ce7711c166492cab2cf926797d6cd9"
          }
        },
        "eb10a63971104ff68f73b41f00a5ee7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f55006915ae3405fbe74dc2c070f925b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9993ee0023f48dfb6ac5cd57b1c3059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30ce7711c166492cab2cf926797d6cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thamizhannal/eva5/blob/master/S10_assignement_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG3TZhHt9rC_",
        "outputId": "f4911c65-6862-4964-b322-508ca586ecad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/JEDI/tsai.jedi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpazjeSHlOIj",
        "outputId": "b69e5076-ed78-48c5-e0db-42fde213315c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!git clone https://github.com/theschoolof-ai/JEDI.git"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'JEDI'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 289 (delta 14), reused 11 (delta 3), pack-reused 256\u001b[K\n",
            "Receiving objects: 100% (289/289), 158.71 MiB | 37.52 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PBsTWgA9ueL",
        "outputId": "e171eaf4-2ec1-450d-9358-a7f8faf76190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/JEDI/tsai.jedi"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/JEDI/tsai.jedi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJpNa66lj1U",
        "outputId": "12808d8c-8e4c-4b96-9cb5-ae304f1ce73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aftereffects.py  dataloader.py         gradcam.py  \u001b[0m\u001b[01;34mmodel_objects\u001b[0m/  README.md\n",
            "batchnorm.py     datatransforms.py     \u001b[01;34mJEDI\u001b[0m/       \u001b[01;34mModels\u001b[0m/\n",
            "config.py        Engine_train_test.py  main.py     \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE5Uz_Jglo56"
      },
      "source": [
        "import sys\n",
        "sys.path.append('Models/')\n",
        "from S8_resnet import ResNet18\n",
        "from S7 import model_summary"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lmEpMC59wKE"
      },
      "source": [
        "import sys\n",
        "sys.path.append('Models/')\n",
        "from S7 import model_summary\n",
        "from S9_resnet import resnet18"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtvINx2R9xz5",
        "outputId": "84d9ce7a-6257-4559-889e-cf6d235fa8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "! pip install albumentations==0.4.6"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.6/dist-packages (0.4.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.18.5)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d244YvVB94Ov"
      },
      "source": [
        "sys.path.append(\".\")\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import config\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from Engine_train_test import train, test\n",
        "from dataloader import train_loader_CIFAR10_alb, test_loader_CIFAR10_alb"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrpg-Fri_pRy",
        "outputId": "f3c0a124-6777-4e16-e1d1-8fd21ac5b1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_ = resnet18(num_classes = 10,pretrained = False).to(config.device)\n",
        "print(model_summary(model_, config.input_size_CIFAR10))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
            "              ReLU-9           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-10           [-1, 64, 32, 32]               0\n",
            "           Conv2d-11           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 32, 32]             128\n",
            "             ReLU-13           [-1, 64, 32, 32]               0\n",
            "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
            "             ReLU-16           [-1, 64, 32, 32]               0\n",
            "       BasicBlock-17           [-1, 64, 32, 32]               0\n",
            "           Conv2d-18          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
            "             ReLU-20          [-1, 128, 16, 16]               0\n",
            "           Conv2d-21          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
            "           Conv2d-23          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
            "             ReLU-25          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-26          [-1, 128, 16, 16]               0\n",
            "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
            "             ReLU-29          [-1, 128, 16, 16]               0\n",
            "           Conv2d-30          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
            "             ReLU-32          [-1, 128, 16, 16]               0\n",
            "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
            "           Conv2d-34            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "             ReLU-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-38            [-1, 256, 8, 8]             512\n",
            "           Conv2d-39            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-40            [-1, 256, 8, 8]             512\n",
            "             ReLU-41            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-42            [-1, 256, 8, 8]               0\n",
            "           Conv2d-43            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-44            [-1, 256, 8, 8]             512\n",
            "             ReLU-45            [-1, 256, 8, 8]               0\n",
            "           Conv2d-46            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-47            [-1, 256, 8, 8]             512\n",
            "             ReLU-48            [-1, 256, 8, 8]               0\n",
            "       BasicBlock-49            [-1, 256, 8, 8]               0\n",
            "           Conv2d-50            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-51            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-52            [-1, 512, 4, 4]               0\n",
            "           Conv2d-53            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-54            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-55            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-60            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-61            [-1, 512, 4, 4]               0\n",
            "           Conv2d-62            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-63            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-64            [-1, 512, 4, 4]               0\n",
            "       BasicBlock-65            [-1, 512, 4, 4]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0\n",
            "           Linear-67                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 15.50\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 58.14\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6j4ZW2Ebjy"
      },
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class train_transform_alb(Dataset):\n",
        "    def __init__(self, image_list, label):\n",
        "        self.image_list = image_list\n",
        "        self.label = label\n",
        "        self.aug = A.Compose([\n",
        "            A.RandomCrop(32, 32, p=0.5),\n",
        "            A.Cutout(num_holes=8,  max_h_size=8, max_w_size=8, p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Rotate((-8.0, 8.0), p=0.5),\n",
        "            A.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image = Image.fromarray(self.image_list[i]).convert('RGB')\n",
        "        image = self.aug(image=np.array(image))['image']\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        label = self.label[i]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class test_transform_alb(Dataset):\n",
        "    def __init__(self, image_list, label):\n",
        "        self.image_list = image_list\n",
        "        self.label = label\n",
        "        self.aug = A.Compose([\n",
        "            A.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image = Image.fromarray(self.image_list[i]).convert('RGB')\n",
        "        image = self.aug(image=np.array(image))['image']\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        label = self.label[i]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJM9UAHo-oa",
        "outputId": "1517afcb-05ba-4e84-f458-f8b1f954e566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "510d309887544e058f8a9a00903d9fe7",
            "555548ac556744dd9200fa19fda1c0af",
            "1cfde7e08e4840a7af2a196196b8f862",
            "135d27ce59db497ab79c847dcd6a5a0f",
            "b4fd94e7af6444c3af5d5cea9718bd80",
            "674d2fe3063b41c896103e76d54ea377",
            "8d54de1ea5e24188b968d369462e95fc",
            "9b287dddf77e45c18616f59108a7eb4a"
          ]
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "lr_finder = LRFinder(model_, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(train_loader_CIFAR10_alb, end_lr=100, num_iter=100, step_mode=\"exp\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "510d309887544e058f8a9a00903d9fe7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T35M22uSpEyP",
        "outputId": "39627c72-d325-4e7d-82c9-ff06d1921941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "\n",
        "lr_finder.plot()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 1.52E-03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.axes._subplots.AxesSubplot at 0x7fc5a120ddd8>,\n",
              " 0.0015199110829529335)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66MbN2FmEA27",
        "outputId": "720c3f18-d7c7-4f24-e8cc-67f46593f954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "3ae5d68485d442848e34c39f24001adf",
            "c48049e83e134da6b6b83fa4f40547ac",
            "8e26b81ce2e84cdb8f342de558be4c2b",
            "3297671b4e0447fb9449d57cfd88cf92",
            "eb10a63971104ff68f73b41f00a5ee7d",
            "f55006915ae3405fbe74dc2c070f925b",
            "c9993ee0023f48dfb6ac5cd57b1c3059",
            "30ce7711c166492cab2cf926797d6cd9"
          ]
        }
      },
      "source": [
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(trainloader, end_lr=100, num_iter=100, step_mode=\"exp\")\n",
        "'''\n",
        "%matplotlib inline\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from __future__ import print_function\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "accu = []\n",
        "loss_test = []\n",
        "\n",
        "# SGD\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_.parameters(), lr=1e-7,  momentum=0.9, weight_decay=1e-2)\n",
        "lr_finder = LRFinder(model_, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(train_loader_CIFAR10_alb, end_lr=100, num_iter=100, step_mode=\"exp\")\n",
        "\n",
        "lr_finder.plot()\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ae5d68485d442848e34c39f24001adf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 5.34E-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.axes._subplots.AxesSubplot at 0x7fc5a1016da0>,\n",
              " 0.053366992312063086)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW_9LepFrRTy",
        "outputId": "137a94c4-4c6e-4a08-99af-f467f05611ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "valid_acc = []\n",
        "loss_test_ = []\n",
        "l1_regularization = [0, 0]\n",
        "\n",
        "# https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "\n",
        "# Assign optimizer with suggested learning rate and run it with reduceonpleatue\n",
        "optimizer = optim.SGD(model_.parameters(), lr=5.34E-02,  momentum=0.9, weight_decay=1e-2)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
        "for epoch in range(100):\n",
        "    train(model_, config.device, train_loader_CIFAR10_alb, optimizer, epoch, l1_regularization=[0, 1])\n",
        "    #scheduler.step()\n",
        "    valid_a, valid_l = test(model_, config.device, test_loader_CIFAR10_alb)\n",
        "    # Appending to loss and accuracy lists\n",
        "    valid_acc.append(valid_a)\n",
        "    loss_test_.append(valid_l)\n",
        "    # Note that step should be called after validate()\n",
        "    scheduler.step(valid_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0,LR: 0.0534.\n",
            "Train set: train Average loss: 1.9904, train_Accuracy: 9933/50000 (19.8660%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.9922471046447754 batch_id=0:   0%|          | 1/391 [00:00<01:10,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0163, Accuracy: 2003/10000 (20.0300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1,LR: 0.0534.\n",
            "Train set: train Average loss: 1.6060, train_Accuracy: 15543/50000 (31.0860%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.5241745710372925 batch_id=0:   0%|          | 1/391 [00:00<01:11,  5.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 3559/10000 (35.5900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2,LR: 0.0534.\n",
            "Train set: train Average loss: 1.2502, train_Accuracy: 22097/50000 (44.1940%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.4134929180145264 batch_id=0:   0%|          | 1/391 [00:00<01:10,  5.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0134, Accuracy: 3996/10000 (39.9600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1139, train_Accuracy: 26483/50000 (52.9660%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.252826452255249 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0126, Accuracy: 4529/10000 (45.2900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1605, train_Accuracy: 28750/50000 (57.5000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.1851407289505005 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0148, Accuracy: 3711/10000 (37.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1140, train_Accuracy: 30357/50000 (60.7140%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.1030703783035278 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0163, Accuracy: 3811/10000 (38.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1425, train_Accuracy: 31310/50000 (62.6200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.1158415079116821 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0133, Accuracy: 4689/10000 (46.8900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7,LR: 0.0534.\n",
            "Train set: train Average loss: 0.8472, train_Accuracy: 31672/50000 (63.3440%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9487375617027283 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0180, Accuracy: 3427/10000 (34.2700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0961, train_Accuracy: 32002/50000 (64.0040%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9534631967544556 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0122, Accuracy: 4868/10000 (48.6800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9732, train_Accuracy: 32055/50000 (64.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9968958497047424 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 4516/10000 (45.1600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0430, train_Accuracy: 32001/50000 (64.0020%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9432909488677979 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 2772/10000 (27.7200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0730, train_Accuracy: 32200/50000 (64.4000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9151278734207153 batch_id=0:   0%|          | 1/391 [00:00<01:12,  5.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0094, Accuracy: 5925/10000 (59.2500%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9310, train_Accuracy: 32177/50000 (64.3540%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.1135972738265991 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0095, Accuracy: 5728/10000 (57.2800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9644, train_Accuracy: 32306/50000 (64.6120%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.015633225440979 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0138, Accuracy: 4443/10000 (44.4300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9644, train_Accuracy: 32156/50000 (64.3120%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.0385735034942627 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0174, Accuracy: 3209/10000 (32.0900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9700, train_Accuracy: 32253/50000 (64.5060%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9710791707038879 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0142, Accuracy: 4226/10000 (42.2600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1547, train_Accuracy: 32082/50000 (64.1640%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.134582281112671 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0138, Accuracy: 4334/10000 (43.3400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0882, train_Accuracy: 32221/50000 (64.4420%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9752064347267151 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0169, Accuracy: 3565/10000 (35.6500%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1748, train_Accuracy: 32066/50000 (64.1320%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9990465641021729 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 3460/10000 (34.6000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0923, train_Accuracy: 32119/50000 (64.2380%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.0940409898757935 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0253, Accuracy: 2731/10000 (27.3100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20,LR: 0.0534.\n",
            "Train set: train Average loss: 1.1119, train_Accuracy: 32010/50000 (64.0200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.8473883271217346 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0123, Accuracy: 4566/10000 (45.6600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21,LR: 0.0534.\n",
            "Train set: train Average loss: 0.9945, train_Accuracy: 32006/50000 (64.0120%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=1.0254713296890259 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0243, Accuracy: 2567/10000 (25.6700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22,LR: 0.0534.\n",
            "Train set: train Average loss: 1.0673, train_Accuracy: 32140/50000 (64.2800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.9952733516693115 batch_id=0:   0%|          | 1/391 [00:00<01:04,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 3233/10000 (32.3300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.8304, train_Accuracy: 37408/50000 (74.8160%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5901218056678772 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 7721/10000 (77.2100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6719, train_Accuracy: 38777/50000 (77.5540%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.44552430510520935 batch_id=0:   0%|          | 1/391 [00:00<01:04,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 7498/10000 (74.9800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6726, train_Accuracy: 39311/50000 (78.6220%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.45658913254737854 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 7528/10000 (75.2800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6720, train_Accuracy: 39370/50000 (78.7400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.6018510460853577 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 7031/10000 (70.3100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6770, train_Accuracy: 39749/50000 (79.4980%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5066347122192383 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0063, Accuracy: 7311/10000 (73.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5443, train_Accuracy: 39792/50000 (79.5840%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.604150652885437 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0057, Accuracy: 7521/10000 (75.2100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.8217, train_Accuracy: 40035/50000 (80.0700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.6104943156242371 batch_id=0:   0%|          | 1/391 [00:00<01:04,  6.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 7697/10000 (76.9700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6593, train_Accuracy: 40200/50000 (80.4000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5722888708114624 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 7494/10000 (74.9400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4414, train_Accuracy: 40536/50000 (81.0720%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5833910703659058 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 7275/10000 (72.7500%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4960, train_Accuracy: 40449/50000 (80.8980%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.710730791091919 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 7478/10000 (74.7800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6091, train_Accuracy: 40569/50000 (81.1380%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5554470419883728 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 7752/10000 (77.5200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5053, train_Accuracy: 40823/50000 (81.6460%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5793507695198059 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0058, Accuracy: 7541/10000 (75.4100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6138, train_Accuracy: 40889/50000 (81.7780%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.39068132638931274 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 7867/10000 (78.6700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.7358, train_Accuracy: 40981/50000 (81.9620%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5703023076057434 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 7686/10000 (76.8600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.7059, train_Accuracy: 40915/50000 (81.8300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5000015497207642 batch_id=0:   0%|          | 1/391 [00:00<01:10,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 7591/10000 (75.9100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6381, train_Accuracy: 41022/50000 (82.0440%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5604435801506042 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0069, Accuracy: 7032/10000 (70.3200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6337, train_Accuracy: 41144/50000 (82.2880%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5135804414749146 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 7804/10000 (78.0400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5002, train_Accuracy: 41123/50000 (82.2460%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.45887619256973267 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 7821/10000 (78.2100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 41,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6805, train_Accuracy: 41403/50000 (82.8060%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.46436989307403564 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 7665/10000 (76.6500%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 42,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6282, train_Accuracy: 41176/50000 (82.3520%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5266516804695129 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0054, Accuracy: 7701/10000 (77.0100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 43,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5301, train_Accuracy: 41216/50000 (82.4320%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4957829415798187 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0070, Accuracy: 7068/10000 (70.6800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 44,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4488, train_Accuracy: 41415/50000 (82.8300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.6257943511009216 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0059, Accuracy: 7509/10000 (75.0900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 45,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5479, train_Accuracy: 41484/50000 (82.9680%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5092562437057495 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 7211/10000 (72.1100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 46,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5806, train_Accuracy: 41469/50000 (82.9380%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.537929892539978 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 7776/10000 (77.7600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 47,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6047, train_Accuracy: 41518/50000 (83.0360%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4184146225452423 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0053, Accuracy: 7645/10000 (76.4500%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 48,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4082, train_Accuracy: 41431/50000 (82.8620%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.49256932735443115 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0057, Accuracy: 7588/10000 (75.8800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5825, train_Accuracy: 41614/50000 (83.2280%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5320754051208496 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0061, Accuracy: 7304/10000 (73.0400%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5089, train_Accuracy: 41632/50000 (83.2640%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.409601628780365 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 8063/10000 (80.6300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 51,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4929, train_Accuracy: 41518/50000 (83.0360%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.40046849846839905 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0044, Accuracy: 8089/10000 (80.8900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 52,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6662, train_Accuracy: 41712/50000 (83.4240%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.31973615288734436 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0044, Accuracy: 8172/10000 (81.7200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 53,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4045, train_Accuracy: 41715/50000 (83.4300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.6419985890388489 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0049, Accuracy: 7939/10000 (79.3900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 54,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.7204, train_Accuracy: 41566/50000 (83.1320%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.542914092540741 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0050, Accuracy: 7802/10000 (78.0200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 55,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6631, train_Accuracy: 41634/50000 (83.2680%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4562234878540039 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 7800/10000 (78.0000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 56,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4546, train_Accuracy: 41755/50000 (83.5100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.501844048500061 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0057, Accuracy: 7553/10000 (75.5300%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 57,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.6027, train_Accuracy: 41699/50000 (83.3980%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4858998954296112 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0062, Accuracy: 7330/10000 (73.3000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 58,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5943, train_Accuracy: 41757/50000 (83.5140%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4413057863712311 batch_id=0:   0%|          | 1/391 [00:00<01:09,  5.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0047, Accuracy: 7970/10000 (79.7000%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 59,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.7286, train_Accuracy: 41777/50000 (83.5540%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.455310195684433 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0052, Accuracy: 7771/10000 (77.7100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 60,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.3730, train_Accuracy: 41799/50000 (83.5980%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4887326657772064 batch_id=0:   0%|          | 1/391 [00:00<01:07,  5.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0051, Accuracy: 7842/10000 (78.4200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 61,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4703, train_Accuracy: 41849/50000 (83.6980%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.4311891794204712 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0074, Accuracy: 6972/10000 (69.7200%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 62,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.4824, train_Accuracy: 41805/50000 (83.6100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.5023055076599121 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0060, Accuracy: 7437/10000 (74.3700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 63,LR: 0.005340000000000001.\n",
            "Train set: train Average loss: 0.5051, train_Accuracy: 41853/50000 (83.7060%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.49655961990356445 batch_id=0:   0%|          | 1/391 [00:00<01:10,  5.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0055, Accuracy: 7661/10000 (76.6100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 64,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.4057, train_Accuracy: 44467/50000 (88.9340%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.38923758268356323 batch_id=0:   0%|          | 1/391 [00:00<01:06,  5.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0031, Accuracy: 8729/10000 (87.2900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 65,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.5322, train_Accuracy: 45405/50000 (90.8100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.35526931285858154 batch_id=0:   0%|          | 1/391 [00:00<01:08,  5.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 8768/10000 (87.6800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 66,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.2983, train_Accuracy: 45682/50000 (91.3640%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.22918462753295898 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 8779/10000 (87.7900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 67,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.2272, train_Accuracy: 45995/50000 (91.9900%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.2878098785877228 batch_id=0:   0%|          | 1/391 [00:00<01:09,  5.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8797/10000 (87.9700%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 68,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.1466, train_Accuracy: 46340/50000 (92.6800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.32537704706192017 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8788/10000 (87.8800%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 69,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.2230, train_Accuracy: 46379/50000 (92.7580%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.22039572894573212 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8806/10000 (88.0600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 70,LR: 0.0005340000000000001.\n",
            "Train set: train Average loss: 0.2468, train_Accuracy: 46567/50000 (93.1340%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.18082799017429352 batch_id=0:   0%|          | 1/391 [00:00<01:05,  5.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8816/10000 (88.1600%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.24890154600143433 batch_id=249:  64%|██████▎   | 249/391 [00:42<00:23,  5.92it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ISDAqABe5lh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwuzdZ7sgAMR"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from packaging import version\n",
        "\n",
        "PYTORCH_VERSION = version.parse(torch.__version__)\n",
        "\n",
        "try:\n",
        "    from apex import amp\n",
        "\n",
        "    IS_AMP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    IS_AMP_AVAILABLE = False\n",
        "\n",
        "\n",
        "class DataLoaderIter(object):\n",
        "    def __init__(self, data_loader):\n",
        "        self.data_loader = data_loader\n",
        "        self._iterator = iter(data_loader)\n",
        "\n",
        "    @property\n",
        "    def dataset(self):\n",
        "        return self.data_loader.dataset\n",
        "\n",
        "    def inputs_labels_from_batch(self, batch_data):\n",
        "        if not isinstance(batch_data, list) and not isinstance(batch_data, tuple):\n",
        "            raise ValueError(\n",
        "                \"Your batch type is not supported: {}. Please inherit from \"\n",
        "                \"`TrainDataLoaderIter` or `ValDataLoaderIter` and override the \"\n",
        "                \"`inputs_labels_from_batch` method.\".format(type(batch_data))\n",
        "            )\n",
        "\n",
        "        inputs, labels, *_ = batch_data\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        batch = next(self._iterator)\n",
        "        return self.inputs_labels_from_batch(batch)\n",
        "\n",
        "\n",
        "class TrainDataLoaderIter(DataLoaderIter):\n",
        "    def __init__(self, data_loader, auto_reset=True):\n",
        "        super().__init__(data_loader)\n",
        "        self.auto_reset = auto_reset\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            batch = next(self._iterator)\n",
        "            inputs, labels = self.inputs_labels_from_batch(batch)\n",
        "        except StopIteration:\n",
        "            if not self.auto_reset:\n",
        "                raise\n",
        "            self._iterator = iter(self.data_loader)\n",
        "            batch = next(self._iterator)\n",
        "            inputs, labels = self.inputs_labels_from_batch(batch)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "\n",
        "class ValDataLoaderIter(DataLoaderIter):\n",
        "    \"\"\"This iterator will reset itself **only** when it is acquired by\n",
        "    the syntax of normal `iterator`. That is, this iterator just works\n",
        "    like a `torch.data.DataLoader`. If you want to restart it, you\n",
        "    should use it like:\n",
        "\n",
        "        ```\n",
        "        loader_iter = ValDataLoaderIter(data_loader)\n",
        "        for batch in loader_iter:\n",
        "            ...\n",
        "\n",
        "        # `loader_iter` should run out of values now, you can restart it by:\n",
        "        # 1. the way we use a `torch.data.DataLoader`\n",
        "        for batch in loader_iter:        # __iter__ is called implicitly\n",
        "            ...\n",
        "\n",
        "        # 2. passing it into `iter()` manually\n",
        "        loader_iter = iter(loader_iter)  # __iter__ is called by `iter()`\n",
        "        ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_loader):\n",
        "        super().__init__(data_loader)\n",
        "        self.run_limit = len(self.data_loader)\n",
        "        self.run_counter = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.run_counter >= self.run_limit:\n",
        "            self._iterator = iter(self.data_loader)\n",
        "            self.run_counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        self.run_counter += 1\n",
        "        return super(ValDataLoaderIter, self).__next__()\n",
        "\n",
        "\n",
        "class LRFinder(object):\n",
        "    \"\"\"Learning rate range test.\n",
        "\n",
        "    The learning rate range test increases the learning rate in a pre-training run\n",
        "    between two boundaries in a linear or exponential manner. It provides valuable\n",
        "    information on how well the network can be trained over a range of learning rates\n",
        "    and what is the optimal learning rate.\n",
        "\n",
        "    Arguments:\n",
        "        model (torch.nn.Module): wrapped model.\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer where the defined learning\n",
        "            is assumed to be the lower boundary of the range test.\n",
        "        criterion (torch.nn.Module): wrapped loss function.\n",
        "        device (str or torch.device, optional): a string (\"cpu\" or \"cuda\") with an\n",
        "            optional ordinal for the device type (e.g. \"cuda:X\", where is the ordinal).\n",
        "            Alternatively, can be an object representing the device on which the\n",
        "            computation will take place. Default: None, uses the same device as `model`.\n",
        "        memory_cache (boolean, optional): if this flag is set to True, `state_dict` of\n",
        "            model and optimizer will be cached in memory. Otherwise, they will be saved\n",
        "            to files under the `cache_dir`.\n",
        "        cache_dir (string, optional): path for storing temporary files. If no path is\n",
        "            specified, system-wide temporary directory is used. Notice that this\n",
        "            parameter will be ignored if `memory_cache` is True.\n",
        "\n",
        "    Example:\n",
        "        >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "        >>> lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n",
        "        >>> lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "        >>> lr_finder.reset() # to reset the model and optimizer to their initial state\n",
        "\n",
        "    Reference:\n",
        "    Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    fastai/lr_find: https://github.com/fastai/fastai\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        device=None,\n",
        "        memory_cache=True,\n",
        "        cache_dir=None,\n",
        "    ):\n",
        "        # Check if the optimizer is already attached to a scheduler\n",
        "        self.optimizer = optimizer\n",
        "        self._check_for_scheduler()\n",
        "\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.history = {\"lr\": [], \"loss\": []}\n",
        "        self.best_loss = None\n",
        "        self.memory_cache = memory_cache\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        # Save the original state of the model and optimizer so they can be restored if\n",
        "        # needed\n",
        "        self.model_device = next(self.model.parameters()).device\n",
        "        self.state_cacher = StateCacher(memory_cache, cache_dir=cache_dir)\n",
        "        self.state_cacher.store(\"model\", self.model.state_dict())\n",
        "        self.state_cacher.store(\"optimizer\", self.optimizer.state_dict())\n",
        "\n",
        "        # If device is None, use the same as the model\n",
        "        if device:\n",
        "            self.device = device\n",
        "        else:\n",
        "            self.device = self.model_device\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Restores the model and optimizer to their initial states.\"\"\"\n",
        "\n",
        "        self.model.load_state_dict(self.state_cacher.retrieve(\"model\"))\n",
        "        self.optimizer.load_state_dict(self.state_cacher.retrieve(\"optimizer\"))\n",
        "        self.model.to(self.model_device)\n",
        "\n",
        "    def range_test(\n",
        "        self,\n",
        "        train_loader,\n",
        "        val_loader=None,\n",
        "        start_lr=None,\n",
        "        end_lr=10,\n",
        "        num_iter=100,\n",
        "        step_mode=\"exp\",\n",
        "        smooth_f=0.05,\n",
        "        diverge_th=5,\n",
        "        accumulation_steps=1,\n",
        "        non_blocking_transfer=True,\n",
        "    ):\n",
        "        \"\"\"Performs the learning rate range test.\n",
        "\n",
        "        Arguments:\n",
        "            train_loader (`torch.utils.data.DataLoader`\n",
        "                or child of `TrainDataLoaderIter`, optional):\n",
        "                the training set data loader.\n",
        "                If your dataset (data loader) returns a tuple (inputs, labels,*) then\n",
        "                Pytorch data loader object can be provided. However, if a dataset\n",
        "                returns different outputs e.g. dicts, then you should inherit\n",
        "                from `TrainDataLoaderIter` class and redefine `inputs_labels_from_batch`\n",
        "                method so that it outputs (inputs, labels).\n",
        "            val_loader (`torch.utils.data.DataLoader`\n",
        "                or child of `ValDataLoaderIter`, optional): if `None` the range test\n",
        "                will only use the training loss. When given a data loader, the model is\n",
        "                evaluated after each iteration on that dataset and the evaluation loss\n",
        "                is used. Note that in this mode the test takes significantly longer but\n",
        "                generally produces more precise results.\n",
        "                Similarly to `train_loader`, if your dataset outputs are not standard\n",
        "                you should inherit from `ValDataLoaderIter` class and\n",
        "                redefine method `inputs_labels_from_batch` so that\n",
        "                it outputs (inputs, labels). Default: None.\n",
        "            start_lr (float, optional): the starting learning rate for the range test.\n",
        "                Default: None (uses the learning rate from the optimizer).\n",
        "            end_lr (float, optional): the maximum learning rate to test. Default: 10.\n",
        "            num_iter (int, optional): the number of iterations over which the test\n",
        "                occurs. Default: 100.\n",
        "            step_mode (str, optional): one of the available learning rate policies,\n",
        "                linear or exponential (\"linear\", \"exp\"). Default: \"exp\".\n",
        "            smooth_f (float, optional): the loss smoothing factor within the [0, 1[\n",
        "                interval. Disabled if set to 0, otherwise the loss is smoothed using\n",
        "                exponential smoothing. Default: 0.05.\n",
        "            diverge_th (int, optional): the test is stopped when the loss surpasses the\n",
        "                threshold:  diverge_th * best_loss. Default: 5.\n",
        "            accumulation_steps (int, optional): steps for gradient accumulation. If it\n",
        "                is 1, gradients are not accumulated. Default: 1.\n",
        "            non_blocking_transfer (bool, optional): when non_blocking_transfer is set,\n",
        "                tries to convert/move data to the device asynchronously if possible,\n",
        "                e.g., moving CPU Tensors with pinned memory to CUDA devices. Default: True.\n",
        "\n",
        "        Example (fastai approach):\n",
        "            >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "            >>> lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n",
        "\n",
        "        Example (Leslie Smith's approach):\n",
        "            >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "            >>> lr_finder.range_test(trainloader, val_loader=val_loader, end_lr=1, num_iter=100, step_mode=\"linear\")\n",
        "\n",
        "        Gradient accumulation is supported; example:\n",
        "            >>> train_data = ...    # prepared dataset\n",
        "            >>> desired_bs, real_bs = 32, 4         # batch size\n",
        "            >>> accumulation_steps = desired_bs // real_bs     # required steps for accumulation\n",
        "            >>> dataloader = torch.utils.data.DataLoader(train_data, batch_size=real_bs, shuffle=True)\n",
        "            >>> acc_lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
        "            >>> acc_lr_finder.range_test(dataloader, end_lr=10, num_iter=100, accumulation_steps=accumulation_steps)\n",
        "\n",
        "        If your DataLoader returns e.g. dict, or other non standard output, intehit from TrainDataLoaderIter,\n",
        "        redefine method `inputs_labels_from_batch` so that it outputs (inputs, lables) data:\n",
        "            >>> import torch_lr_finder\n",
        "            >>> class TrainIter(torch_lr_finder.TrainDataLoaderIter):\n",
        "            >>>     def inputs_labels_from_batch(self, batch_data):\n",
        "            >>>         return (batch_data['user_features'], batch_data['user_history']), batch_data['y_labels']\n",
        "            >>> train_data_iter = TrainIter(train_dl)\n",
        "            >>> finder = torch_lr_finder.LRFinder(model, optimizer, partial(model._train_loss, need_one_hot=False))\n",
        "            >>> finder.range_test(train_data_iter, end_lr=10, num_iter=300, diverge_th=10)\n",
        "\n",
        "        Reference:\n",
        "        [Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU & Distributed setups](\n",
        "        https://medium.com/huggingface/ec88c3e51255)\n",
        "        [thomwolf/gradient_accumulation](https://gist.github.com/thomwolf/ac7a7da6b1888c2eeac8ac8b9b05d3d3)\n",
        "        \"\"\"\n",
        "\n",
        "        # Reset test results\n",
        "        self.history = {\"lr\": [], \"loss\": []}\n",
        "        self.best_loss = None\n",
        "\n",
        "        # Move the model to the proper device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Check if the optimizer is already attached to a scheduler\n",
        "        self._check_for_scheduler()\n",
        "\n",
        "        # Set the starting learning rate\n",
        "        if start_lr:\n",
        "            self._set_learning_rate(start_lr)\n",
        "\n",
        "        # Initialize the proper learning rate policy\n",
        "        if step_mode.lower() == \"exp\":\n",
        "            lr_schedule = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        elif step_mode.lower() == \"linear\":\n",
        "            lr_schedule = LinearLR(self.optimizer, end_lr, num_iter)\n",
        "        else:\n",
        "            raise ValueError(\"expected one of (exp, linear), got {}\".format(step_mode))\n",
        "\n",
        "        if smooth_f < 0 or smooth_f >= 1:\n",
        "            raise ValueError(\"smooth_f is outside the range [0, 1[\")\n",
        "\n",
        "        # Create an iterator to get data batch by batch\n",
        "        if isinstance(train_loader, DataLoader):\n",
        "            train_iter = TrainDataLoaderIter(train_loader)\n",
        "        elif isinstance(train_loader, TrainDataLoaderIter):\n",
        "            train_iter = train_loader\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"`train_loader` has unsupported type: {}.\"\n",
        "                \"Expected types are `torch.utils.data.DataLoader`\"\n",
        "                \"or child of `TrainDataLoaderIter`.\".format(type(train_loader))\n",
        "            )\n",
        "\n",
        "        if val_loader:\n",
        "            if isinstance(val_loader, DataLoader):\n",
        "                val_iter = ValDataLoaderIter(val_loader)\n",
        "            elif isinstance(val_loader, ValDataLoaderIter):\n",
        "                val_iter = val_loader\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    \"`val_loader` has unsupported type: {}.\"\n",
        "                    \"Expected types are `torch.utils.data.DataLoader`\"\n",
        "                    \"or child of `ValDataLoaderIter`.\".format(type(val_loader))\n",
        "                )\n",
        "\n",
        "        for iteration in tqdm(range(num_iter)):\n",
        "            # Train on batch and retrieve loss\n",
        "            loss = self._train_batch(\n",
        "                train_iter,\n",
        "                accumulation_steps,\n",
        "                non_blocking_transfer=non_blocking_transfer,\n",
        "            )\n",
        "            if val_loader:\n",
        "                loss = self._validate(\n",
        "                    val_iter, non_blocking_transfer=non_blocking_transfer\n",
        "                )\n",
        "\n",
        "            # Update the learning rate\n",
        "            self.history[\"lr\"].append(lr_schedule.get_lr()[0])\n",
        "            lr_schedule.step()\n",
        "\n",
        "            # Track the best loss and smooth it if smooth_f is specified\n",
        "            if iteration == 0:\n",
        "                self.best_loss = loss\n",
        "            else:\n",
        "                if smooth_f > 0:\n",
        "                    loss = smooth_f * loss + (1 - smooth_f) * self.history[\"loss\"][-1]\n",
        "                if loss < self.best_loss:\n",
        "                    self.best_loss = loss\n",
        "\n",
        "            # Check if the loss has diverged; if it has, stop the test\n",
        "            self.history[\"loss\"].append(loss)\n",
        "            if loss > diverge_th * self.best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "\n",
        "        print(\"Learning rate search finished. See the graph with {finder_name}.plot()\")\n",
        "\n",
        "    def _set_learning_rate(self, new_lrs):\n",
        "        if not isinstance(new_lrs, list):\n",
        "            new_lrs = [new_lrs] * len(self.optimizer.param_groups)\n",
        "        if len(new_lrs) != len(self.optimizer.param_groups):\n",
        "            raise ValueError(\n",
        "                \"Length of `new_lrs` is not equal to the number of parameter groups \"\n",
        "                + \"in the given optimizer\"\n",
        "            )\n",
        "\n",
        "        for param_group, new_lr in zip(self.optimizer.param_groups, new_lrs):\n",
        "            param_group[\"lr\"] = new_lr\n",
        "\n",
        "    def _check_for_scheduler(self):\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            if \"initial_lr\" in param_group:\n",
        "                raise RuntimeError(\"Optimizer already has a scheduler attached to it\")\n",
        "\n",
        "    def _train_batch(self, train_iter, accumulation_steps, non_blocking_transfer=True):\n",
        "        self.model.train()\n",
        "        total_loss = None  # for late initialization\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        for i in range(accumulation_steps):\n",
        "            inputs, labels = next(train_iter)\n",
        "            inputs, labels = self._move_to_device(\n",
        "                inputs, labels, non_blocking=non_blocking_transfer\n",
        "            )\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Loss should be averaged in each step\n",
        "            loss /= accumulation_steps\n",
        "\n",
        "            # Backward pass\n",
        "            if IS_AMP_AVAILABLE and hasattr(self.optimizer, \"_amp_stash\"):\n",
        "                # For minor performance optimization, see also:\n",
        "                # https://nvidia.github.io/apex/advanced.html#gradient-accumulation-across-iterations\n",
        "                delay_unscale = ((i + 1) % accumulation_steps) != 0\n",
        "\n",
        "                with amp.scale_loss(\n",
        "                    loss, self.optimizer, delay_unscale=delay_unscale\n",
        "                ) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            if total_loss is None:\n",
        "                total_loss = loss\n",
        "            else:\n",
        "                total_loss += loss\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return total_loss.item()\n",
        "\n",
        "    def _move_to_device(self, inputs, labels, non_blocking=True):\n",
        "        def move(obj, device, non_blocking=True):\n",
        "            if hasattr(obj, \"to\"):\n",
        "                return obj.to(device, non_blocking=non_blocking)\n",
        "            elif isinstance(obj, tuple):\n",
        "                return tuple(move(o, device, non_blocking) for o in obj)\n",
        "            elif isinstance(obj, list):\n",
        "                return [move(o, device, non_blocking) for o in obj]\n",
        "            elif isinstance(obj, dict):\n",
        "                return {k: move(o, device, non_blocking) for k, o in obj.items()}\n",
        "            else:\n",
        "                return obj\n",
        "\n",
        "        inputs = move(inputs, self.device, non_blocking=non_blocking)\n",
        "        labels = move(labels, self.device, non_blocking=non_blocking)\n",
        "        return inputs, labels\n",
        "\n",
        "    def _validate(self, val_iter, non_blocking_transfer=True):\n",
        "        # Set model to evaluation mode and disable gradient computation\n",
        "        running_loss = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_iter:\n",
        "                # Move data to the correct device\n",
        "                inputs, labels = self._move_to_device(\n",
        "                    inputs, labels, non_blocking=non_blocking_transfer\n",
        "                )\n",
        "\n",
        "                # Forward pass and loss computation\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                running_loss += loss.item() * len(labels)\n",
        "\n",
        "        return running_loss / len(val_iter.dataset)\n",
        "\n",
        "    def plot(\n",
        "        self,\n",
        "        skip_start=10,\n",
        "        skip_end=5,\n",
        "        log_lr=True,\n",
        "        show_lr=None,\n",
        "        ax=None,\n",
        "        suggest_lr=True,\n",
        "    ):\n",
        "        \"\"\"Plots the learning rate range test.\n",
        "\n",
        "        Arguments:\n",
        "            skip_start (int, optional): number of batches to trim from the start.\n",
        "                Default: 10.\n",
        "            skip_end (int, optional): number of batches to trim from the start.\n",
        "                Default: 5.\n",
        "            log_lr (bool, optional): True to plot the learning rate in a logarithmic\n",
        "                scale; otherwise, plotted in a linear scale. Default: True.\n",
        "            show_lr (float, optional): if set, adds a vertical line to visualize the\n",
        "                specified learning rate. Default: None.\n",
        "            ax (matplotlib.axes.Axes, optional): the plot is created in the specified\n",
        "                matplotlib axes object and the figure is not be shown. If `None`, then\n",
        "                the figure and axes object are created in this method and the figure is\n",
        "                shown . Default: None.\n",
        "            suggest_lr (bool, optional): suggest a learning rate by\n",
        "                - 'steepest': the point with steepest gradient (minimal gradient)\n",
        "                you can use that point as a first guess for an LR. Default: True.\n",
        "\n",
        "        Returns:\n",
        "            The matplotlib.axes.Axes object that contains the plot,\n",
        "            and the suggested learning rate (if set suggest_lr=True).\n",
        "        \"\"\"\n",
        "\n",
        "        if skip_start < 0:\n",
        "            raise ValueError(\"skip_start cannot be negative\")\n",
        "        if skip_end < 0:\n",
        "            raise ValueError(\"skip_end cannot be negative\")\n",
        "        if show_lr is not None and not isinstance(show_lr, float):\n",
        "            raise ValueError(\"show_lr must be float\")\n",
        "\n",
        "        # Get the data to plot from the history dictionary. Also, handle skip_end=0\n",
        "        # properly so the behaviour is the expected\n",
        "        lrs = self.history[\"lr\"]\n",
        "        losses = self.history[\"loss\"]\n",
        "        if skip_end == 0:\n",
        "            lrs = lrs[skip_start:]\n",
        "            losses = losses[skip_start:]\n",
        "        else:\n",
        "            lrs = lrs[skip_start:-skip_end]\n",
        "            losses = losses[skip_start:-skip_end]\n",
        "\n",
        "        # Create the figure and axes object if axes was not already given\n",
        "        fig = None\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots()\n",
        "\n",
        "        # Plot loss as a function of the learning rate\n",
        "        ax.plot(lrs, losses)\n",
        "\n",
        "        # Plot the suggested LR\n",
        "        if suggest_lr:\n",
        "            # 'steepest': the point with steepest gradient (minimal gradient)\n",
        "            print(\"LR suggestion: steepest gradient\")\n",
        "            min_grad_idx = None\n",
        "            try:\n",
        "                min_grad_idx = (np.gradient(np.array(losses))).argmin()\n",
        "            except ValueError:\n",
        "                print(\n",
        "                    \"Failed to compute the gradients, there might not be enough points.\"\n",
        "                )\n",
        "            if min_grad_idx is not None:\n",
        "                print(\"Suggested LR: {:.2E}\".format(lrs[min_grad_idx]))\n",
        "                ax.scatter(\n",
        "                    lrs[min_grad_idx],\n",
        "                    losses[min_grad_idx],\n",
        "                    s=75,\n",
        "                    marker=\"o\",\n",
        "                    color=\"red\",\n",
        "                    zorder=3,\n",
        "                    label=\"steepest gradient\",\n",
        "                )\n",
        "                ax.legend()\n",
        "\n",
        "        if log_lr:\n",
        "            ax.set_xscale(\"log\")\n",
        "        ax.set_xlabel(\"Learning rate\")\n",
        "        ax.set_ylabel(\"Loss\")\n",
        "\n",
        "        if show_lr is not None:\n",
        "            ax.axvline(x=show_lr, color=\"red\")\n",
        "\n",
        "        # Show only if the figure was created internally\n",
        "        if fig is not None:\n",
        "            plt.show()\n",
        "\n",
        "        if suggest_lr and min_grad_idx:\n",
        "            return ax, lrs[min_grad_idx]\n",
        "        else:\n",
        "            return ax\n",
        "\n",
        "\n",
        "class LinearLR(_LRScheduler):\n",
        "    \"\"\"Linearly increases the learning rate between two boundaries over a number of\n",
        "    iterations.\n",
        "\n",
        "    Arguments:\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
        "        end_lr (float): the final learning rate.\n",
        "        num_iter (int): the number of iterations over which the test occurs.\n",
        "        last_epoch (int, optional): the index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "\n",
        "        if num_iter <= 1:\n",
        "            raise ValueError(\"`num_iter` must be larger than 1\")\n",
        "        self.num_iter = num_iter\n",
        "\n",
        "        super(LinearLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        # In earlier Pytorch versions last_epoch starts at -1, while in recent versions\n",
        "        # it starts at 0. We need to adjust the math a bit to handle this. See\n",
        "        # discussion at: https://github.com/davidtvs/pytorch-lr-finder/pull/42\n",
        "        if PYTORCH_VERSION < version.parse(\"1.1.0\"):\n",
        "            curr_iter = self.last_epoch + 1\n",
        "            r = curr_iter / (self.num_iter - 1)\n",
        "        else:\n",
        "            r = self.last_epoch / (self.num_iter - 1)\n",
        "\n",
        "        return [base_lr + r * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    \"\"\"Exponentially increases the learning rate between two boundaries over a number of\n",
        "    iterations.\n",
        "\n",
        "    Arguments:\n",
        "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
        "        end_lr (float): the final learning rate.\n",
        "        num_iter (int): the number of iterations over which the test occurs.\n",
        "        last_epoch (int, optional): the index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "\n",
        "        if num_iter <= 1:\n",
        "            raise ValueError(\"`num_iter` must be larger than 1\")\n",
        "        self.num_iter = num_iter\n",
        "\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        # In earlier Pytorch versions last_epoch starts at -1, while in recent versions\n",
        "        # it starts at 0. We need to adjust the math a bit to handle this. See\n",
        "        # discussion at: https://github.com/davidtvs/pytorch-lr-finder/pull/42\n",
        "        if PYTORCH_VERSION < version.parse(\"1.1.0\"):\n",
        "            curr_iter = self.last_epoch + 1\n",
        "            r = curr_iter / (self.num_iter - 1)\n",
        "        else:\n",
        "            r = self.last_epoch / (self.num_iter - 1)\n",
        "\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class StateCacher(object):\n",
        "    def __init__(self, in_memory, cache_dir=None):\n",
        "        self.in_memory = in_memory\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if self.cache_dir is None:\n",
        "            import tempfile\n",
        "\n",
        "            self.cache_dir = tempfile.gettempdir()\n",
        "        else:\n",
        "            if not os.path.isdir(self.cache_dir):\n",
        "                raise ValueError(\"Given `cache_dir` is not a valid directory.\")\n",
        "\n",
        "        self.cached = {}\n",
        "\n",
        "    def store(self, key, state_dict):\n",
        "        if self.in_memory:\n",
        "            self.cached.update({key: copy.deepcopy(state_dict)})\n",
        "        else:\n",
        "            fn = os.path.join(self.cache_dir, \"state_{}_{}.pt\".format(key, id(self)))\n",
        "            self.cached.update({key: fn})\n",
        "            torch.save(state_dict, fn)\n",
        "\n",
        "    def retrieve(self, key):\n",
        "        if key not in self.cached:\n",
        "            raise KeyError(\"Target {} was not cached.\".format(key))\n",
        "\n",
        "        if self.in_memory:\n",
        "            return self.cached.get(key)\n",
        "        else:\n",
        "            fn = self.cached.get(key)\n",
        "            if not os.path.exists(fn):\n",
        "                raise RuntimeError(\n",
        "                    \"Failed to load state in {}. File doesn't exist anymore.\".format(fn)\n",
        "                )\n",
        "            state_dict = torch.load(fn, map_location=lambda storage, location: storage)\n",
        "            return state_dict\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Check whether there are unused cached files existing in `cache_dir` before\n",
        "        this instance being destroyed.\"\"\"\n",
        "\n",
        "        if self.in_memory:\n",
        "            return\n",
        "\n",
        "        for k in self.cached:\n",
        "            if os.path.exists(self.cached[k]):\n",
        "                os.remove(self.cached[k])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeQObsgigAzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}